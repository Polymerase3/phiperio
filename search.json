[{"path":"https://polymerase3.github.io/phiperio/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to phiperio","title":"Contributing to phiperio","text":"outlines propose change phiperio.","code":""},{"path":"https://polymerase3.github.io/phiperio/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to phiperio","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://polymerase3.github.io/phiperio/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to phiperio","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed). See guide create great issue advice.","code":""},{"path":"https://polymerase3.github.io/phiperio/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to phiperio","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"Polymerase3/phiperio\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://polymerase3.github.io/phiperio/CONTRIBUTING.html","id":"versioning-pre-100","dir":"","previous_headings":"Bigger changes","what":"Versioning (pre-1.0.0)","title":"Contributing to phiperio","text":"follow semver pre-1.0.0 rules: Breaking changes (API changes behavior changes require user updates) => minor bump (e.g. 0.1.0 -> 0.2.0). Non-breaking changes (features, fixes, refactors, docs) => patch bump (e.g. 0.2.3 -> 0.2.4). PR include appropriate version bump DESCRIPTION matching entry NEWS.md.","code":""},{"path":"https://polymerase3.github.io/phiperio/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to phiperio","text":"New code follow tidyverse style guide. can use Air apply style, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://polymerase3.github.io/phiperio/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://polymerase3.github.io/phiperio/articles/importing-long-tidy-data.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Importing cross-sectional and longitudinal tidy data with phiperio","text":"vignette shows, step step, import cross-sectional longitudinal PhIP-Seq data convert_standard(), inspect manipulate resulting <phip_data> object, export . Explanations written first‑time users - plenty comments plain language.","code":""},{"path":"https://polymerase3.github.io/phiperio/articles/importing-long-tidy-data.html","id":"key-concepts-read-first","dir":"Articles","previous_headings":"","what":"Key concepts (read first)","title":"Importing cross-sectional and longitudinal tidy data with phiperio","text":"sample_id - must unique per sample/assay run. example: identifies single well 96-well plate. subject_id - identifies person/test subject. cross-sectional data subject_id == sample_id, can omit . longitudinal data, subject_id appears across multiple sample_ids (different timepoints). Outcomes: need least one exist, fold_change, raw counts (counts_input, counts_hit). Format: long table (one row per sample_id × peptide_id).","code":""},{"path":"https://polymerase3.github.io/phiperio/articles/importing-long-tidy-data.html","id":"cross-sectional-workflow-simpler","dir":"Articles","previous_headings":"","what":"Cross-sectional workflow (simpler)","title":"Importing cross-sectional and longitudinal tidy data with phiperio","text":"cross-sectional data subject exactly one sample, subject_id == sample_id need supply subject_id. Inspect manipulate: Export Parquet:","code":"# ---- 1) Make a tiny cross-sectional long table ---------------------------- # One subject = one sample; sample_id is unique and also identifies the subject cross_long <- data.frame(   sample_id   = c(\"s1\", \"s1\", \"s2\", \"s2\"),  # unique sample IDs   peptide_id  = c(\"p1\", \"p2\", \"p1\", \"p2\"),  # peptide identifiers   exist       = c(1, 0, 0, 1),              # example outcome (binary)   fold_change = c(1.2, 0.8, 0.4, 2.0),      # non‑negative fold-change   age         = c(34, 34, 58, 58),          # per-sample metadata   sex         = c(\"F\", \"F\", \"M\", \"M\"),      # per-sample metadata   stringsAsFactors = FALSE )  # Print the tiny table so you can see the structure: cross_long #>   sample_id peptide_id exist fold_change age sex #> 1        s1         p1     1         1.2  34   F #> 2        s1         p2     0         0.8  34   F #> 3        s2         p1     0         0.4  58   M #> 4        s2         p2     1         2.0  58   M # Each row is a sample_id × peptide_id combination. # exist/fold_change are measurements; age/sex are sample-level metadata.  # Save to CSV (you could also use Parquet). convert_standard reads either. xc_csv <- tempfile(fileext = \".csv\") utils::write.csv(cross_long, xc_csv, row.names = FALSE)  # ---- 2) Import with convert_standard -------------------------------------- # Because column names already match the defaults, we only pass the file path. pd_xc <- convert_standard(   data_long_path    = xc_csv,   peptide_library   = TRUE,    # attach peptide annotations   materialise_table = FALSE    # keep as a view for fast iterations ) #> Skipping ANALYZE - raw_combined is a view. #> [12:00:33] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:33] INFO  Fetching peptide metadata library via get_peptide_library() #> [12:00:33] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:33] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:33] OK    Using cached peptide_meta (fast path) #> [12:00:33] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 0.24s #> [12:00:33] OK    Peptide metadata acquired #> [12:00:33] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:33] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:33] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:33] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:33] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:33] INFO  Checking key uniqueness #> [12:00:33] INFO  Validating value ranges & types for outcomes #> Warning: Missing values are always removed in SQL aggregation functions. #> Use `na.rm = TRUE` to silence this warning #> This warning is displayed once every 8 hours. #> [12:00:33] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:33] INFO  Checking peptide_id coverage against peptide_library #> Warning: [12:00:33] WARN  peptide_id not found in peptide_library (e.g. p1) #>                  -> peptide library coverage. #> [12:00:33] INFO  Checking full grid completeness (peptide * sample) #> [12:00:33] OK    Counts table is a full peptide * sample grid #> [12:00:33] OK    Validating <phip_data> - done #>                  -> elapsed: 0.679s #> [12:00:33] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.923s # The peptide library comes from the companion repo # https://github.com/Polymerase3/phiper and is maintained by our group with # collaborator-provided annotations. Setting peptide_library = TRUE pulls the # current cached version automatically. # Show the phip_data object (prints a concise summary) pd_xc #> ── <phip_data> ─────────────────────────────────────────────────────────────────  #>  #> counts (first 5 rows):  #> # A tibble: 4 × 6 #>   sample_id peptide_id exist fold_change   age sex   #>   <chr>     <chr>      <dbl>       <dbl> <dbl> <chr> #> 1 s1        p1             1         1.2    34 F     #> 2 s1        p2             0         0.8    34 F     #> 3 s2        p1             0         0.4    58 M     #> 4 s2        p2             1         2      58 M     #>  #> table size: 4 rows x 6 columns #>  #> peptide library preview (first 5 rows):  #> # A tibble: 5 × 8 #>   peptide_id Fullname                    species genus family order class common #>   <chr>      <chr>                       <chr>   <chr> <chr>  <chr> <chr> <chr>  #> 1 agilent_1  Chromodomain-helicase-DNA-… Homo s… Homo  Homin… Prim… Mamm… Human  #> 2 agilent_2  integral membrane protein   Mycoba… Myco… Mycob… Myco… Acti… NA     #> 3 agilent_3  hypothetical protein (6/16… Mycoba… Myco… Mycob… Myco… Acti… NA     #> 4 agilent_4  envelope protein (5/8) & a… Orthof… Orth… Flavi… Amar… Flas… JEV    #> 5 agilent_5  Myosin-7 & beta-myosin hea… Homo s… Homo  Homin… Prim… Mamm… Human  #> ... plus 36 more columns #>  #> library size: 357,190 rows x 44 columns #>  #> meta flags:  #>   con:            <duckdb_connection> #>   longitudinal:   FALSE #>   exist:          TRUE #>   fold_change:    TRUE #>   raw_counts:     FALSE #>   extra_cols:     age, sex #>   peptide_con:    <duckdb_connection> #>   materialise_table: FALSE #>   finalizer_env:  <environment> #>   full_cross:     TRUE  # Peek at the long table lazily (no data pulled yet) # get_counts() returns the same table as pd_xc$data_long get_counts(pd_xc) #> # Source:   table<raw_combined> [?? x 6] #> # Database: DuckDB 1.4.4 [unknown@Linux 6.11.0-1018-azure:R 4.5.2//tmp/RtmpURoYj3/phiperio_cache1ea93de57bdc/phip_cache.duckdb] #>   sample_id peptide_id exist fold_change   age sex   #>   <chr>     <chr>      <dbl>       <dbl> <dbl> <chr> #> 1 s1        p1             1         1.2    34 F     #> 2 s1        p2             0         0.8    34 F     #> 3 s2        p1             0         0.4    58 M     #> 4 s2        p2             1         2      58 M  # Filter to positive fold_change and collect to R pd_xc_pos <- pd_xc |>   dplyr::filter(fold_change > 0) |>   dplyr::select(sample_id, peptide_id, fold_change) |>   dplyr::collect()  pd_xc_pos #> # A tibble: 4 × 3 #>   sample_id peptide_id fold_change #>   <chr>     <chr>            <dbl> #> 1 s1        p1                 1.2 #> 2 s1        p2                 0.8 #> 3 s2        p1                 0.4 #> 4 s2        p2                 2 out_parquet <- tempfile(fileext = \".parquet\") export_parquet(pd_xc, out_parquet) out_parquet #> [1] \"/tmp/RtmpURoYj3/file1ea9bad6d83.parquet\"  # Re-import the Parquet file directly with convert_standard() pd_xc_again <- convert_standard(   data_long_path = out_parquet,   peptide_library = TRUE,   materialise_table = FALSE ) #> Skipping ANALYZE - raw_combined is a view. #> [12:00:34] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:34] INFO  Fetching peptide metadata library via get_peptide_library() #> [12:00:34] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:34] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:34] OK    Using cached peptide_meta (fast path) #> [12:00:34] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 0.214s #> [12:00:34] OK    Peptide metadata acquired #> [12:00:34] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:34] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:34] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:34] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:34] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:34] INFO  Checking key uniqueness #> [12:00:34] INFO  Validating value ranges & types for outcomes #> [12:00:34] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:34] INFO  Checking peptide_id coverage against peptide_library #> Warning: [12:00:35] WARN  peptide_id not found in peptide_library (e.g. p1) #>                  -> peptide library coverage. #> [12:00:35] INFO  Checking full grid completeness (peptide * sample) #> [12:00:35] OK    Counts table is a full peptide * sample grid #> [12:00:35] OK    Validating <phip_data> - done #>                  -> elapsed: 0.479s #> [12:00:35] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.695s pd_xc_again #> ── <phip_data> ─────────────────────────────────────────────────────────────────  #>  #> counts (first 5 rows):  #> # A tibble: 4 × 6 #>   sample_id peptide_id exist fold_change   age sex   #>   <chr>     <chr>      <dbl>       <dbl> <dbl> <chr> #> 1 s1        p1             1         1.2    34 F     #> 2 s1        p2             0         0.8    34 F     #> 3 s2        p1             0         0.4    58 M     #> 4 s2        p2             1         2      58 M     #>  #> table size: 4 rows x 6 columns #>  #> peptide library preview (first 5 rows):  #> # A tibble: 5 × 8 #>   peptide_id Fullname                    species genus family order class common #>   <chr>      <chr>                       <chr>   <chr> <chr>  <chr> <chr> <chr>  #> 1 agilent_1  Chromodomain-helicase-DNA-… Homo s… Homo  Homin… Prim… Mamm… Human  #> 2 agilent_2  integral membrane protein   Mycoba… Myco… Mycob… Myco… Acti… NA     #> 3 agilent_3  hypothetical protein (6/16… Mycoba… Myco… Mycob… Myco… Acti… NA     #> 4 agilent_4  envelope protein (5/8) & a… Orthof… Orth… Flavi… Amar… Flas… JEV    #> 5 agilent_5  Myosin-7 & beta-myosin hea… Homo s… Homo  Homin… Prim… Mamm… Human  #> ... plus 36 more columns #>  #> library size: 357,190 rows x 44 columns #>  #> meta flags:  #>   con:            <duckdb_connection> #>   longitudinal:   FALSE #>   exist:          TRUE #>   fold_change:    TRUE #>   raw_counts:     FALSE #>   extra_cols:     age, sex #>   peptide_con:    <duckdb_connection> #>   materialise_table: FALSE #>   finalizer_env:  <environment> #>   full_cross:     TRUE"},{"path":"https://polymerase3.github.io/phiperio/articles/importing-long-tidy-data.html","id":"longitudinal-workflow-subjects-with-multiple-samples","dir":"Articles","previous_headings":"","what":"Longitudinal workflow (subjects with multiple samples)","title":"Importing cross-sectional and longitudinal tidy data with phiperio","text":", subject_id must provided link multiple sample_ids belong subject. also include timepoint column can track visits. Work longitudinal data: Export longitudinal data:","code":"# ---- 1) Build a tiny longitudinal long table ------------------------------ # subject_id repeats across samples; sample_id stays unique per draw/run long_long <- data.frame(   subject_id   = c(\"subj1\", \"subj1\", \"subj1\", \"subj2\", \"subj2\", \"subj2\"),   sample_id    = c(\"s1_t1\", \"s1_t2\", \"s1_t3\", \"s2_t1\", \"s2_t2\", \"s2_t3\"),   timepoint    = c(\"T1\", \"T2\", \"T3\", \"T1\", \"T2\", \"T3\"),     # visit labels   peptide_id   = c(\"p1\", \"p1\", \"p2\", \"p1\", \"p2\", \"p2\"),   exist        = c(1, 1, 0, 0, 1, 1),   fold_change  = c(1.5, 1.1, 0.2, 0.8, 1.9, 2.5),            # non‑negative   input_reads  = c(1200, 1300, 800, 900, 1500, 1700),        # counts_input (custom name)   hit_reads    = c(12, 15, 4, 5, 22, 28),                    # counts_hit (custom name)   run_id       = c(\"runA\", \"runA\", \"runA\", \"runB\", \"runB\", \"runB\"),   plate_id     = c(\"plate1\", \"plate1\", \"plate1\", \"plate2\", \"plate2\", \"plate2\"),   stringsAsFactors = FALSE )  lg_csv <- tempfile(fileext = \".csv\") utils::write.csv(long_long, lg_csv, row.names = FALSE)  # ---- 2) Import with subject_id and timepoint ------------------------------ pd_lg <- convert_standard(   data_long_path    = lg_csv,   subject_id        = \"subject_id\",  # explicitly map subject_id   timepoint         = \"timepoint\",   # map timepoint column   counts_input      = \"input_reads\", # map custom raw-count columns   counts_hit        = \"hit_reads\",   peptide_library   = FALSE,   auto_expand       = FALSE,         # keep as-is; set TRUE to fill full grid   materialise_table = FALSE ) #> Skipping ANALYZE - raw_combined is a view. #> [12:00:35] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:35] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:35] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:35] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:35] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:35] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:35] INFO  Checking key uniqueness #> [12:00:35] INFO  Validating value ranges & types for outcomes #> [12:00:35] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:35] INFO  Checking peptide_id coverage against peptide_library #> [12:00:35] INFO  Checking full grid completeness (peptide * sample) #> Warning: [12:00:35] WARN  Counts table is not a full peptide * sample grid. #>                  -> grid completeness #>                    - observed rows: 6 #>                    - expected rows: 12. #> Warning: [12:00:35] WARN  Grid remains incomplete (auto_expand = FALSE). #>                  -> grid completeness #>                    - observed rows: 6 #>                    - expected rows: 12. #> [12:00:35] OK    Validating <phip_data> - done #>                  -> elapsed: 0.35s #> [12:00:35] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.351s # Look at the object summary pd_lg #> ── <phip_data> ─────────────────────────────────────────────────────────────────  #>  #> counts (first 5 rows):  #> # A tibble: 5 × 10 #>   subject_id sample_id timepoint peptide_id exist fold_change counts_input #>   <chr>      <chr>     <chr>     <chr>      <dbl>       <dbl>        <dbl> #> 1 subj1      s1_t1     T1        p1             1         1.5         1200 #> 2 subj1      s1_t2     T2        p1             1         1.1         1300 #> 3 subj1      s1_t3     T3        p2             0         0.2          800 #> 4 subj2      s2_t1     T1        p1             0         0.8          900 #> 5 subj2      s2_t2     T2        p2             1         1.9         1500 #> # ℹ 3 more variables: counts_hit <dbl>, run_id <chr>, plate_id <chr> #>  #> table size: 6 rows x 10 columns #>  #> peptide library preview (first 5 rows):  #> meta flags:  #>   con:            <duckdb_connection> #>   longitudinal:   TRUE #>   exist:          TRUE #>   fold_change:    TRUE #>   raw_counts:     TRUE #>   extra_cols:     run_id, plate_id #>   materialise_table: FALSE #>   finalizer_env:  <environment> #>   full_cross:     FALSE  # Filter to one subject and collect pd_lg_subj1 <- pd_lg |>   dplyr::filter(subject_id == \"subj1\") |>   dplyr::collect()  pd_lg_subj1 #> # A tibble: 3 × 10 #>   subject_id sample_id timepoint peptide_id exist fold_change counts_input #>   <chr>      <chr>     <chr>     <chr>      <dbl>       <dbl>        <dbl> #> 1 subj1      s1_t1     T1        p1             1         1.5         1200 #> 2 subj1      s1_t2     T2        p1             1         1.1         1300 #> 3 subj1      s1_t3     T3        p2             0         0.2          800 #> # ℹ 3 more variables: counts_hit <dbl>, run_id <chr>, plate_id <chr>  # Compute average fold_change per subject across timepoints (lazy until collect) pd_lg_avg <- pd_lg |>   dplyr::group_by(subject_id) |>   dplyr::summarise(mean_fc = mean(fold_change, na.rm = TRUE)) |>   dplyr::collect()  pd_lg_avg #> # A tibble: 2 × 2 #>   subject_id mean_fc #>   <chr>        <dbl> #> 1 subj1        0.933 #> 2 subj2        1.73  # Inspect extra columns (metadata not part of the standard set) pd_lg$meta$extra_cols  # should list run_id and plate_id #> [1] \"run_id\"   \"plate_id\" out_parquet_lg <- tempfile(fileext = \".parquet\") export_parquet(pd_lg, out_parquet_lg) out_parquet_lg #> [1] \"/tmp/RtmpURoYj3/file1ea96053adf6.parquet\""},{"path":"https://polymerase3.github.io/phiperio/articles/importing-long-tidy-data.html","id":"tips-and-gotchas","dir":"Articles","previous_headings":"","what":"Tips and gotchas","title":"Importing cross-sectional and longitudinal tidy data with phiperio","text":"Uniqueness: sample_id must unique per sample. cross-sectional data also serves subject identifier; longitudinal data use subject_id connect multiple sample_ids. Column mapping: column names differ, map function arguments (sample_id, peptide_id, subject_id, timepoint, etc.). Auto-expand: set auto_expand = TRUE fill missing sample_id × peptide_id combinations (measurement columns filled 0 overrides). Peptide library: set peptide_library = TRUE attach metadata; keep FALSE quick examples offline runs.","code":""},{"path":"https://polymerase3.github.io/phiperio/articles/importing-long-tidy-data.html","id":"using-the-built-in-example","dir":"Articles","previous_headings":"","what":"Using the built-in example","title":"Importing cross-sectional and longitudinal tidy data with phiperio","text":"","code":"ex <- load_example_data() #> [12:00:36] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:36] INFO  Fetching peptide metadata library via get_peptide_library() #> [12:00:36] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:36] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:36] OK    Using cached peptide_meta (fast path) #> [12:00:36] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 0.207s #> [12:00:36] OK    Peptide metadata acquired #> [12:00:36] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:36] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:36] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:36] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:36] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:36] INFO  Checking key uniqueness #> [12:00:36] INFO  Validating value ranges & types for outcomes #> [12:00:36] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:36] INFO  Checking peptide_id coverage against peptide_library #> Warning: [12:00:37] WARN  peptide_id not found in peptide_library (e.g. 10003) #>                  -> peptide library coverage. #> [12:00:37] INFO  Checking full grid completeness (peptide * sample) #> Warning: [12:00:37] WARN  Counts table is not a full peptide * sample grid. #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> Warning: [12:00:37] WARN  Grid remains incomplete (auto_expand = FALSE). #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> [12:00:37] OK    Validating <phip_data> - done #>                  -> elapsed: 0.571s #> [12:00:37] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.779s ex #> ── <phip_data> ─────────────────────────────────────────────────────────────────  #>  #> counts (first 5 rows):  #> # A tibble: 5 × 9 #>   sample_id subject_id group timepoint peptide_id exist counts_control #>   <chr>     <chr>      <chr> <chr>     <chr>      <int>          <int> #> 1 A_T1_1    1          A     T1        10003          1              5 #> 2 A_T1_1    1          A     T1        10017          1             37 #> 3 A_T1_1    1          A     T1        10023          1             11 #> 4 A_T1_1    1          A     T1        10062          1              0 #> 5 B_T1_1    1          B     T1        10087          1              1 #> # ℹ 2 more variables: counts_hits <int>, fold_change <dbl> #>  #> table size: 78,200 rows x 9 columns #>  #> peptide library preview (first 5 rows):  #> # A tibble: 5 × 8 #>   peptide_id Fullname                    species genus family order class common #>   <chr>      <chr>                       <chr>   <chr> <chr>  <chr> <chr> <chr>  #> 1 agilent_1  Chromodomain-helicase-DNA-… Homo s… Homo  Homin… Prim… Mamm… Human  #> 2 agilent_2  integral membrane protein   Mycoba… Myco… Mycob… Myco… Acti… NA     #> 3 agilent_3  hypothetical protein (6/16… Mycoba… Myco… Mycob… Myco… Acti… NA     #> 4 agilent_4  envelope protein (5/8) & a… Orthof… Orth… Flavi… Amar… Flas… JEV    #> 5 agilent_5  Myosin-7 & beta-myosin hea… Homo s… Homo  Homin… Prim… Mamm… Human  #> ... plus 36 more columns #>  #> library size: 357,190 rows x 44 columns #>  #> meta flags:  #>   con:            <duckdb_connection> #>   longitudinal:   TRUE #>   exist:          TRUE #>   fold_change:    TRUE #>   raw_counts:     FALSE #>   extra_cols:     group, counts_control, counts_hits #>   peptide_con:    <duckdb_connection> #>   materialise_table: TRUE #>   finalizer_env:  <environment> #>   full_cross:     FALSE"},{"path":"https://polymerase3.github.io/phiperio/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mateusz Kolek. Author, maintainer, copyright holder. Alon Alexander. Contributor, copyright holder.","code":""},{"path":"https://polymerase3.github.io/phiperio/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kolek M (2026). phiperio: PhIP-Seq Data Import Validation Tools. R package version 0.4.0, https://github.com/Polymerase3/phiperio.","code":"@Manual{,   title = {phiperio: PhIP-Seq Data Import and Validation Tools},   author = {Mateusz Kolek},   year = {2026},   note = {R package version 0.4.0},   url = {https://github.com/Polymerase3/phiperio}, }"},{"path":"https://polymerase3.github.io/phiperio/index.html","id":"phiperio","dir":"","previous_headings":"","what":"phiperio - PhIP-Seq tidy data pipeline","title":"phiperio - PhIP-Seq tidy data pipeline","text":"phiperio package provides utilities import, validate, manage PhIP-Seq datasets, including standardized conversion pipelines, data checks, access cached peptide metadata.","code":""},{"path":"https://polymerase3.github.io/phiperio/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"phiperio - PhIP-Seq tidy data pipeline","text":"can install development version phiperio GitHub either pak devtools:","code":"# install.packages(\"pak\") pak::pak(\"Polymerase3/phiperio\")  # or, using devtools: # install.packages(\"devtools\") devtools::install_github(\"Polymerase3/phiperio\")"},{"path":"https://polymerase3.github.io/phiperio/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"phiperio - PhIP-Seq tidy data pipeline","text":"guided walk-(cross-sectional longitudinal imports), see vignette pkgdown site: Importing long tidy data phiperio. Minimal one-liner load package:","code":"library(phiperio)"},{"path":"https://polymerase3.github.io/phiperio/index.html","id":"aim-and-key-features","dir":"","previous_headings":"","what":"Aim and key features","title":"phiperio - PhIP-Seq tidy data pipeline","text":"phiperio focuses reliable ingest validation PhIP-Seq data, downstream analyses start clean, standardized base. Key features include: DuckDB backend + Parquet first: uses DuckDB hood writes/reads Parquet default transaction layer phiper data source phiperio, giving fast /O great interoperability. Scales millions rows: lazy database pipelines Parquet storage let work efficiently large PhIP-Seq datasets. Import helpers common PhIP-Seq inputs peptide metadata (peptide library cached maintained companion phiper repo). Strong validation consistency checks catch data issues early. Lightweight, reproducible pipelines standardize raw inputs <phip_data> objects.","code":""},{"path":"https://polymerase3.github.io/phiperio/index.html","id":"minimal-usage","dir":"","previous_headings":"","what":"Minimal usage","title":"phiperio - PhIP-Seq tidy data pipeline","text":"","code":"library(phiperio)  # See available helpers and functions ?phiperio"},{"path":"https://polymerase3.github.io/phiperio/index.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"phiperio - PhIP-Seq tidy data pipeline","text":"Spotted bug want request feature? Please open issue: https://github.com/Polymerase3/phiperio/issues","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/add_exist.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensure an existence flag (all ones) on data_long — add_exist","title":"Ensure an existence flag (all ones) on data_long — add_exist","text":"Appends/overwrites column (default: \"exist\") filled 1L lazy data_long table. Preserves laziness; collection forced.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/add_exist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ensure an existence flag (all ones) on data_long — add_exist","text":"","code":"add_exist(phip_data, exist_col = \"exist\", overwrite = FALSE)"},{"path":"https://polymerase3.github.io/phiperio/reference/add_exist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensure an existence flag (all ones) on data_long — add_exist","text":"phip_data <phip_data> object. exist_col Name existence column append/overwrite. overwrite FALSE column exists, abort phiperio-style error.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/add_exist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ensure an existence flag (all ones) on data_long — add_exist","text":"Modified <phip_data> updated data_long.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/add_exist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ensure an existence flag (all ones) on data_long — add_exist","text":"","code":"pd <- load_example_data() #> [12:00:08] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:08] INFO  Fetching peptide metadata library via get_peptide_library() #> [12:00:08] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:08] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:08] INFO  Starting download #>                    - dest: #>                      /home/runner/.cache/R/phiperio/peptide_meta/combined_library_15.01.26.rds #> [12:00:08] OK    Download succeeded (method = <getOption()>) #> [12:00:09] OK    Checksum verified (SHA-256 match) #> [12:00:11] OK    Download complete and loaded into R #> [12:00:17] INFO  Importing sanitized metadata into DuckDB cache... #> [12:00:18] OK    peptide_meta table created in DuckDB cache #> [12:00:18] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 9.995s #> [12:00:18] OK    Peptide metadata acquired #> [12:00:18] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:18] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:18] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:18] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:18] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:18] INFO  Checking key uniqueness #> [12:00:18] INFO  Validating value ranges & types for outcomes #> Warning: Missing values are always removed in SQL aggregation functions. #> Use `na.rm = TRUE` to silence this warning #> This warning is displayed once every 8 hours. #> [12:00:18] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:19] INFO  Checking peptide_id coverage against peptide_library #> Warning: [12:00:19] WARN  peptide_id not found in peptide_library (e.g. 10003) #>                  -> peptide library coverage. #> [12:00:19] INFO  Checking full grid completeness (peptide * sample) #> Warning: [12:00:19] WARN  Counts table is not a full peptide * sample grid. #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> Warning: [12:00:19] WARN  Grid remains incomplete (auto_expand = FALSE). #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> [12:00:19] OK    Validating <phip_data> - done #>                  -> elapsed: 0.664s #> [12:00:19] OK    Constructing <phip_data> object - done #>                  -> elapsed: 10.662s pd <- add_exist(pd, overwrite = TRUE) # overwrites if present #> [12:00:19] INFO  Ensuring existence flag on data_long #>                  -> column: 'exist'; overwrite: TRUE #> Warning: [12:00:19] WARN  Overwriting existing existence flag. #>                  -> adding existence indicator #>                    - column: \"exist\". #> [12:00:19] OK    Ensuring existence flag on data_long - done #>                  -> elapsed: 0.008s"},{"path":"https://polymerase3.github.io/phiperio/reference/close.phip_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Close phip_data connections — close.phip_data","title":"Close phip_data connections — close.phip_data","text":"Closes open database connections held phip_data object. includes main data_long backend connection peptide-library connection stored attributes metadata. method idempotent safe call multiple times.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/close.phip_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Close phip_data connections — close.phip_data","text":"","code":"# S3 method for class 'phip_data' close(con, ...)"},{"path":"https://polymerase3.github.io/phiperio/reference/close.phip_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Close phip_data connections — close.phip_data","text":"con valid phip_data object. ... Unused (S3 generic compatibility).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/close.phip_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Close phip_data connections — close.phip_data","text":"input phip_data object, invisibly.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/close.phip_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Close phip_data connections — close.phip_data","text":"","code":"pd <- load_example_data() close(pd)"},{"path":"https://polymerase3.github.io/phiperio/reference/convert_legacy.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","title":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","text":"convert_legacy() ingests original three-file PhIP-Seq input (binary exist matrix, samples metadata, optional timepoints map). Paths can supplied directly via single YAML config; explicit arguments always override YAML.  function normalises chosen DuckDB storage, validates every file, returns ready--use phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_legacy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","text":"","code":"convert_legacy(   exist_file = NULL,   fold_change_file = NULL,   samples_file = NULL,   input_file = NULL,   hit_file = NULL,   timepoints_file = NULL,   extra_cols = NULL,   output_dir = NULL,   peptide_library = TRUE,   n_cores = 8,   materialise_table = TRUE,   config_yaml = NULL )"},{"path":"https://polymerase3.github.io/phiperio/reference/convert_legacy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","text":"exist_file Path exist CSV (peptide x sample binary matrix). Required unless given config_yaml. fold_change_file Path fold_change CSV (peptide x sample numeric matrix). Required unless given config_yaml. samples_file Path samples CSV (sample metadata). Required unless given config_yaml. input_file, hit_file Paths raw_counts CSV (peptide x sample integer matrix). Required unless given config_yaml. timepoints_file Path timepoints CSV (subject <-> sample mapping). Optional cross-sectional data. extra_cols Character vector extra metadata columns retain. output_dir Deprecated. Ignored warning. peptide_library logical, defining peptide_library downloaded official phiperio GitHub n_cores Integer >= 1. Number CPU threads DuckDB may use reading writing files. materialise_table Logical. FALSE result registered view; TRUE table fully materialised stored disk, trading higher load time storage faster repeated queries. config_yaml Optional YAML file containing parameters (see example).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_legacy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","text":"validated phip_data object whose data_long slot backed DuckDB connection.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_legacy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","text":"Input files validated two stages: Fast-fail checks (paths, extensions, required arguments) run path resolution. Data validation (required columns, uniqueness, value ranges, etc.) centralized validate_phip_data().","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_legacy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert legacy Carlos-style input to a modern phip_data object — convert_legacy","text":"","code":"## 1. Direct-path usage (package example files) ext <- system.file(\"extdata\", package = \"phiperio\") pd <- convert_legacy(   exist_file = file.path(ext, \"exist.csv\"),   samples_file = file.path(ext, \"samples_meta.csv\"),   timepoints_file = file.path(ext, \"samples2ind_timepoints.csv\"),   peptide_library = FALSE ) #> [12:00:19] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:19] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:19] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:19] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:19] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:19] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:19] INFO  Checking key uniqueness #> [12:00:19] INFO  Validating value ranges & types for outcomes #> [12:00:19] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:20] INFO  Checking peptide_id coverage against peptide_library #> [12:00:20] INFO  Checking full grid completeness (peptide * sample) #> [12:00:20] OK    Counts table is a full peptide * sample grid #> [12:00:20] OK    Validating <phip_data> - done #>                  -> elapsed: 0.294s #> [12:00:20] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.295s  ## 2. YAML-driven usage (explicit args override YAML) pd <- convert_legacy(   config_yaml = file.path(ext, \"config.yaml\"),   peptide_library = FALSE ) #> Warning: [12:00:20] WARN  'output_dir' is deprecated and will be ignored. #> [12:00:20] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:20] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:20] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:20] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:20] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:20] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:20] INFO  Checking key uniqueness #> [12:00:20] INFO  Validating value ranges & types for outcomes #> [12:00:20] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:20] INFO  Checking peptide_id coverage against peptide_library #> [12:00:20] INFO  Checking full grid completeness (peptide * sample) #> [12:00:20] OK    Counts table is a full peptide * sample grid #> [12:00:20] OK    Validating <phip_data> - done #>                  -> elapsed: 0.284s #> [12:00:20] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.285s"},{"path":"https://polymerase3.github.io/phiperio/reference/convert_standard.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","title":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","text":"convert_standard() ingests \"long\" table PhIPsSeq read counts / enrichment statistics, optionally expands full sample_id x peptide_id grid, registers result DuckDB. function returns fully initialised phip_data object can queried tidy API used throughout package.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_standard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","text":"","code":"convert_standard(   data_long_path,   sample_id = NULL,   peptide_id = NULL,   subject_id = NULL,   timepoint = NULL,   exist = NULL,   fold_change = NULL,   counts_input = NULL,   counts_hit = NULL,   n_cores = 8,   materialise_table = TRUE,   auto_expand = FALSE,   peptide_library = TRUE )"},{"path":"https://polymerase3.github.io/phiperio/reference/convert_standard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","text":"data_long_path Character scalar. File directory containing long-format PhIP-Seq data. Allowed extensions .csv .parquet. Directories treated partitions parquet set. sample_id, peptide_id, subject_id, timepoint, exist, fold_change, counts_input, counts_hit Optional character strings. Supply column names differ defaults (\"sample_id\", \"peptide_id\", \"subject_id\", \"timepoint\", \"exist\", \"fold_change\", \"counts_input\", \"counts_hit\"). argument contain name column incoming data; NULL lets default stand. n_cores Integer >= 1. Number CPU threads DuckDB may use reading writing files. materialise_table Logical. FALSE result registered view; TRUE table fully materialised stored disk, trading higher load time storage faster repeated queries. auto_expand Logical. TRUE incoming data complete Cartesian product sample_id x peptide_id, missing combinations generated: Columns constant within sample_id (metadata) copied new rows. Non-recyclable measurement columns (fold_change, exist, counts_input, counts_hit, etc.) initialised 0. expanded table replaces original place. peptide_library Logical. TRUE (default) convert_standard() attempt locate attach matching peptide-library metadata downstream annotation. Set FALSE skip step.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_standard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","text":"S3 object class phip_data containing: data_long (possibly expanded) long-format table. peptide_library Loaded peptide-library metadata (peptide_library = TRUE). meta List DuckDB connection handles.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/convert_standard.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","text":"Paths resolved absolute form work begins, explicit checks confirm existence well extension validity.","code":""},{"path":[]},{"path":"https://polymerase3.github.io/phiperio/reference/convert_standard.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert raw PhIP-Seq output into a phip_data object — convert_standard","text":"","code":"# Basic import, auto-detecting default column names phip_obj <- convert_standard(   data_long_path = get_example_path(\"phip_mixture\"),   n_cores = 4,   materialise_table = TRUE ) #> [12:00:21] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:21] INFO  Fetching peptide metadata library via get_peptide_library() #> [12:00:21] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:21] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:21] OK    Using cached peptide_meta (fast path) #> [12:00:21] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 0.05s #> [12:00:21] OK    Peptide metadata acquired #> [12:00:21] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:21] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:21] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:21] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:21] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:21] INFO  Checking key uniqueness #> [12:00:21] INFO  Validating value ranges & types for outcomes #> [12:00:21] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:21] INFO  Checking peptide_id coverage against peptide_library #> Warning: [12:00:21] WARN  peptide_id not found in peptide_library (e.g. 10003) #>                  -> peptide library coverage. #> [12:00:21] INFO  Checking full grid completeness (peptide * sample) #> Warning: [12:00:21] WARN  Counts table is not a full peptide * sample grid. #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> Warning: [12:00:21] WARN  Grid remains incomplete (auto_expand = FALSE). #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> [12:00:21] OK    Validating <phip_data> - done #>                  -> elapsed: 0.628s #> [12:00:21] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.679s  # Import a CSV and rename columns tmp_csv <- tempfile(fileext = \".csv\") utils::write.csv(   data.frame(     sample = c(\"s1\", \"s1\"),     pep = c(\"p1\", \"p2\"),     exist = c(1, 0),     stringsAsFactors = FALSE   ),   tmp_csv,   row.names = FALSE ) phip_mem <- convert_standard(   data_long_path = tmp_csv,   sample_id      = \"sample\",   peptide_id     = \"pep\",   peptide_library = FALSE,   materialise_table = FALSE ) #> Skipping ANALYZE - raw_combined is a view. #> [12:00:21] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:21] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:21] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:21] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:21] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:21] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:21] INFO  Checking key uniqueness #> [12:00:21] INFO  Validating value ranges & types for outcomes #> [12:00:21] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:21] INFO  Checking peptide_id coverage against peptide_library #> [12:00:21] INFO  Checking full grid completeness (peptide * sample) #> [12:00:22] OK    Counts table is a full peptide * sample grid #> [12:00:22] OK    Validating <phip_data> - done #>                  -> elapsed: 0.273s #> [12:00:22] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.274s"},{"path":"https://polymerase3.github.io/phiperio/reference/create_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a phip_data object — create_data","title":"Construct a phip_data object — create_data","text":"Creates fully-validated S3 object bundles tidy PhIP-Seq counts (data_long), peptide-library annotation table, metadata. data validated via validate_phip_data().","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/create_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a phip_data object — create_data","text":"","code":"create_data(   data_long,   peptide_library = TRUE,   auto_expand = TRUE,   materialise_table = TRUE,   meta = list() )"},{"path":"https://polymerase3.github.io/phiperio/reference/create_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a phip_data object — create_data","text":"data_long tidy data frame (tbl_lazy) one row per peptide_id x sample_id combination. Required. peptide_library data frame one row per peptide_id annotations.  NULL, package’s current default library used. auto_expand Logical. TRUE input already full Cartesian product sample_id x peptide_id, function fills missing combinations. Columns constant within sample_id (metadata) duplicated newly created rows. Measurement columns fold_change, exist, raw counts, non-recyclable fields initialised 0. expanded table replaces data_long place. materialise_table Logical. FALSE (default) result registered view. TRUE result fully materialised stored physical table, speeds repeated queries cost extra memory/disk. meta Optional named list metadata flags pre-populate meta slot (rarely needed users).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/create_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a phip_data object — create_data","text":"object class \"phip_data\".","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/create_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a phip_data object — create_data","text":"","code":"## minimal constructor call tidy_counts <- data.frame(   sample_id = c(\"s1\", \"s1\"),   peptide_id = c(\"p1\", \"p2\"),   exist = c(1, 0),   stringsAsFactors = FALSE ) pd <- create_data(   data_long = tidy_counts,   peptide_library = FALSE,   materialise_table = FALSE ) #> [12:00:22] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:22] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:22] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:22] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:22] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:22] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:22] INFO  Checking key uniqueness #> [12:00:22] INFO  Validating value ranges & types for outcomes #> [12:00:22] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:22] INFO  Checking peptide_id coverage against peptide_library #> [12:00:22] INFO  Checking full grid completeness (peptide * sample) #> [12:00:22] OK    Counts table is a full peptide * sample grid #> [12:00:22] OK    Validating <phip_data> - done #>                  -> elapsed: 0.018s #> [12:00:22] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.019s"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_abort.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_abort — .ph_abort","title":"Internal helper: .ph_abort — .ph_abort","text":"Emit ERROR log block abort execution.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_abort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_abort — .ph_abort","text":"","code":".ph_abort(headline, step = NULL, bullets = NULL, ...)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_add_quotes.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_add_quotes — .ph_add_quotes","title":"Internal helper: .ph_add_quotes — .ph_add_quotes","text":"Wrap character values quotes log output. Supports FALSE/TRUE, 0/1/2, single-character quote string.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_add_quotes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_add_quotes — .ph_add_quotes","text":"","code":".ph_add_quotes(x, quotes = 2L)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_attach_finalizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Attach an auto-finalizer for phip_data connections — .ph_attach_finalizer","title":"Attach an auto-finalizer for phip_data connections — .ph_attach_finalizer","text":"Creates small environment stores current connection handles registers finalizer close object GC'd.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_attach_finalizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attach an auto-finalizer for phip_data connections — .ph_attach_finalizer","text":"","code":".ph_attach_finalizer(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_attach_finalizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attach an auto-finalizer for phip_data connections — .ph_attach_finalizer","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_attach_finalizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Attach an auto-finalizer for phip_data connections — .ph_attach_finalizer","text":"phip_data object attached finalizer environment.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_auto_read_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Read CSV/TSV/Parquet with delimiter sniffing — .ph_auto_read_file","title":"Read CSV/TSV/Parquet with delimiter sniffing — .ph_auto_read_file","text":".ph_auto_read_file() loads delimited text parquet files, detecting delimiter text inputs using duckdb DBI parquet.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_auto_read_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read CSV/TSV/Parquet with delimiter sniffing — .ph_auto_read_file","text":"","code":".ph_auto_read_file(path, ...)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_auto_read_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read CSV/TSV/Parquet with delimiter sniffing — .ph_auto_read_file","text":"path Character scalar. Path CSV/TSV parquet file. ... Additional arguments passed underlying reader.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_auto_read_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read CSV/TSV/Parquet with delimiter sniffing — .ph_auto_read_file","text":"data.frame containing parsed file contents.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_base_prefix.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_base_prefix — .ph_base_prefix","title":"Internal helper: .ph_base_prefix — .ph_base_prefix","text":"Build base log prefix given level label.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_base_prefix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_base_prefix — .ph_base_prefix","text":"","code":".ph_base_prefix(level = \"INFO\")"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_cond.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_check_cond — .ph_check_cond","title":"Internal helper: .ph_check_cond — .ph_check_cond","text":"Execute expression start/stop timing logs.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_cond.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_check_cond — .ph_check_cond","text":"","code":".ph_check_cond(   condition,   error_message,   error = TRUE,   step = NULL,   bullets = NULL,   ... )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_extension.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_check_extension — .ph_check_extension","title":"Internal helper: .ph_check_extension — .ph_check_extension","text":"Validate filename extension allowed set.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_extension.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_check_extension — .ph_check_extension","text":"","code":".ph_check_extension(name, x_name, ext_vec)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_null_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_check_null_default — .ph_check_null_default","title":"Internal helper: .ph_check_null_default — .ph_check_null_default","text":"Replace NULL default, logging warning.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_null_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_check_null_default — .ph_check_null_default","text":"","code":".ph_check_null_default(x, x_name, method, default)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_check_path — .ph_check_path","title":"Internal helper: .ph_check_path — .ph_check_path","text":"Validate file directory path (optional extension).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_check_path — .ph_check_path","text":"","code":".ph_check_path(path, arg_name, extension, is_dir = FALSE)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_pd.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_check_pd — .ph_check_pd","title":"Internal helper: .ph_check_pd — .ph_check_pd","text":"Validate object phip_data instance.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_check_pd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_check_pd — .ph_check_pd","text":"","code":".ph_check_pd(obj)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_clear_connections.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear connection references in a phip_data object — .ph_clear_connections","title":"Clear connection references in a phip_data object — .ph_clear_connections","text":"Internal helper removes stored DBI connections meta slot peptide-library attributes.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_clear_connections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear connection references in a phip_data object — .ph_clear_connections","text":"","code":".ph_clear_connections(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_clear_connections.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear connection references in a phip_data object — .ph_clear_connections","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_clear_connections.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear connection references in a phip_data object — .ph_clear_connections","text":"phip_data object connection references cleared.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_close_phip_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Close connections referenced by a phip_data object — .ph_close_phip_data","title":"Close connections referenced by a phip_data object — .ph_close_phip_data","text":"Internal helper disconnects tracked connections optionally clears connection references stored object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_close_phip_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Close connections referenced by a phip_data object — .ph_close_phip_data","text":"","code":".ph_close_phip_data(x, clear = TRUE)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_close_phip_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Close connections referenced by a phip_data object — .ph_close_phip_data","text":"x valid phip_data object. clear Logical; TRUE, clear connection references closing.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_close_phip_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Close connections referenced by a phip_data object — .ph_close_phip_data","text":"phip_data object closed (possibly cleared) connections.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_collect_connections.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect all connection handles from a phip_data object — .ph_collect_connections","title":"Collect all connection handles from a phip_data object — .ph_collect_connections","text":"Internal helper gathers known DBI connections meta peptide-library attributes, de-duplicated identity.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_collect_connections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect all connection handles from a phip_data object — .ph_collect_connections","text":"","code":".ph_collect_connections(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_collect_connections.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect all connection handles from a phip_data object — .ph_collect_connections","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_collect_connections.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect all connection handles from a phip_data object — .ph_collect_connections","text":"list unique DBI connections.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_compose_lines.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_compose_lines — .ph_compose_lines","title":"Internal helper: .ph_compose_lines — .ph_compose_lines","text":"Compose multi-line log output headline, step, bullets.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_compose_lines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_compose_lines — .ph_compose_lines","text":"","code":".ph_compose_lines(level, headline, step = NULL, bullets = NULL)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_expand_full_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_expand_full_grid — .ph_expand_full_grid","title":"Internal helper: .ph_expand_full_grid — .ph_expand_full_grid","text":"Expand table full key * id grid typed fill defaults.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_expand_full_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_expand_full_grid — .ph_expand_full_grid","text":"","code":".ph_expand_full_grid(   tbl,   key_col = \"sample_id\",   id_col = \"peptide_id\",   fill_override = NULL,   add_exist = FALSE,   exist_col = \"exist\",   validate = TRUE )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_extract_data_long.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_extract_data_long — .ph_extract_data_long","title":"Internal helper: .ph_extract_data_long — .ph_extract_data_long","text":"Return data_long slot input phip_data; otherwise return input unchanged.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_extract_data_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_extract_data_long — .ph_extract_data_long","text":"","code":".ph_extract_data_long(obj)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_prepare_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare sample metadata for legacy import — .ph_legacy_prepare_metadata","title":"Prepare sample metadata for legacy import — .ph_legacy_prepare_metadata","text":"Reads samples_file timepoints_file, merges present add subject identifier timepoint variable.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_prepare_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare sample metadata for legacy import — .ph_legacy_prepare_metadata","text":"","code":".ph_legacy_prepare_metadata(   samples_file,   timepoints_file = NULL,   extra_cols = character() )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_prepare_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare sample metadata for legacy import — .ph_legacy_prepare_metadata","text":"samples_file Absolute path samples CSV/Parquet. timepoints_file Absolute path timepoints CSV/Parquet, NULL. extra_cols Character vector extra metadata columns keep.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_prepare_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare sample metadata for legacy import — .ph_legacy_prepare_metadata","text":"list elements samples, timepoints, extra_cols.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_read_duckdb_backend.html","id":null,"dir":"Reference","previous_headings":"","what":"Build legacy tables in DuckDB for conversion — .ph_legacy_read_duckdb_backend","title":"Build legacy tables in DuckDB for conversion — .ph_legacy_read_duckdb_backend","text":".ph_legacy_read_duckdb_backend() loads legacy CSV/parquet inputs temporary DuckDB tables, reshapes long format, prepares final tables used convert_legacy().","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_read_duckdb_backend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build legacy tables in DuckDB for conversion — .ph_legacy_read_duckdb_backend","text":"","code":".ph_legacy_read_duckdb_backend(cfg, meta)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_read_duckdb_backend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build legacy tables in DuckDB for conversion — .ph_legacy_read_duckdb_backend","text":"cfg Named list resolved file paths options .ph_resolve_paths(). meta List preprocessed metadata tables .ph_legacy_prepare_metadata().","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_read_duckdb_backend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build legacy tables in DuckDB for conversion — .ph_legacy_read_duckdb_backend","text":"DuckDB DBI connection containing temporary final tables needed legacy conversion.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_legacy_read_duckdb_backend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build legacy tables in DuckDB for conversion — .ph_legacy_read_duckdb_backend","text":"rows collected R; transformations executed DuckDB. caller responsible closing returned connection.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_log_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_log_info — .ph_log_info","title":"Internal helper: .ph_log_info — .ph_log_info","text":"Emit INFO log block verbose logging enabled.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_log_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_log_info — .ph_log_info","text":"","code":".ph_log_info(   headline,   step = NULL,   bullets = NULL,   verbose = .ph_opt(\"verbose\", TRUE) )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_log_ok.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_log_ok — .ph_log_ok","title":"Internal helper: .ph_log_ok — .ph_log_ok","text":"Emit OK log block verbose logging enabled.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_log_ok.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_log_ok — .ph_log_ok","text":"","code":".ph_log_ok(   headline,   step = NULL,   bullets = NULL,   verbose = .ph_opt(\"verbose\", TRUE) )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_modify_pd.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_modify_pd — .ph_modify_pd","title":"Internal helper: .ph_modify_pd — .ph_modify_pd","text":"Replace data_long phip_data object return .","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_modify_pd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_modify_pd — .ph_modify_pd","text":"","code":".ph_modify_pd(.data, new_counts)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_now.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_now — .ph_now","title":"Internal helper: .ph_now — .ph_now","text":"Return current time formatted log prefixes.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_now.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_now — .ph_now","text":"","code":".ph_now()"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_opt.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_opt — .ph_opt","title":"Internal helper: .ph_opt — .ph_opt","text":"Read phiperio logging option fallback default.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_opt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_opt — .ph_opt","text":"","code":".ph_opt(key, default = NULL)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_refresh_finalizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Refresh finalizer connection list — .ph_refresh_finalizer","title":"Refresh finalizer connection list — .ph_refresh_finalizer","text":"Updates finalizer environment current connections.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_refresh_finalizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refresh finalizer connection list — .ph_refresh_finalizer","text":"","code":".ph_refresh_finalizer(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_refresh_finalizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refresh finalizer connection list — .ph_refresh_finalizer","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_refresh_finalizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refresh finalizer connection list — .ph_refresh_finalizer","text":"phip_data object refreshed finalizer connections.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_register_phip_data_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a lazy table back to the database as a TABLE or VIEW — .ph_register_phip_data_tbl","title":"Register a lazy table back to the database as a TABLE or VIEW — .ph_register_phip_data_tbl","text":"Convenience wrapper either materialises lazy pipeline via dplyr::compute() (creating TABLE) emits CREATE [TEMP] VIEW ... (creating VIEW). Returns dplyr::tbl() pointing created object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_register_phip_data_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a lazy table back to the database as a TABLE or VIEW — .ph_register_phip_data_tbl","text":"","code":".ph_register_phip_data_tbl(   tbl,   con,   name = \"data_long\",   materialise_table = TRUE,   temporary = TRUE )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_register_phip_data_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a lazy table back to the database as a TABLE or VIEW — .ph_register_phip_data_tbl","text":"tbl lazy table (e.g., dbplyr). con DBI connection. name Target name create (default \"data_long\"). materialise_table TRUE, create TABLE via compute(). FALSE, create VIEW. temporary TRUE, create TEMP table/view supported.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_register_phip_data_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Register a lazy table back to the database as a TABLE or VIEW — .ph_register_phip_data_tbl","text":"lazy dplyr::tbl referencing new TABLE/VIEW.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_rename_to_standard_inplace.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename columns to PHIPERIO standard names in-place — .ph_rename_to_standard_inplace","title":"Rename columns to PHIPERIO standard names in-place — .ph_rename_to_standard_inplace","text":".ph_rename_to_standard_inplace() renames columns DuckDB table view standard PHIPERIO schema using mapping standard names source columns. views, recreates view aliased columns; tables, issues ALTER TABLE ... RENAME COLUMN statements.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_rename_to_standard_inplace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename columns to PHIPERIO standard names in-place — .ph_rename_to_standard_inplace","text":"","code":".ph_rename_to_standard_inplace(tbl, con, colname_map)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_rename_to_standard_inplace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename columns to PHIPERIO standard names in-place — .ph_rename_to_standard_inplace","text":"tbl Character scalar. Name DuckDB table view modify. con valid DBI connection DuckDB. colname_map Named character list mapping standard PHIPERIO column names (e.g. \"sample_id\", \"peptide_id\") actual column names present tbl.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_rename_to_standard_inplace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename columns to PHIPERIO standard names in-place — .ph_rename_to_standard_inplace","text":"Invisibly returns tbl applying renames.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_rename_to_standard_inplace.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rename columns to PHIPERIO standard names in-place — .ph_rename_to_standard_inplace","text":"columns present tbl renamed. views, existing definition retrieved wrapped new CREATE REPLACE VIEW statement aliased columns. matching columns found, function emits message exits.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_resolve_paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve legacy-import paths and perform fast-fail argument checks — .ph_resolve_paths","title":"Resolve legacy-import paths and perform fast-fail argument checks — .ph_resolve_paths","text":"Combines explicit arguments YAML config (given), expands every relative path absolute path (relative paths evaluated dirname(config_yaml) (!!!) YAML used, otherwise directory contains first supplied data matrix (!!!)), returns fully populated list file locations options ready downstream conversion. cheap, load-blocking checks done : input_file hit_file must supplied together omitted. least one matrix source (exist_file, fold_change_file, input_file + hit_file pair) must present. Deprecated output_dir triggers soft warning. deeper table-content validation deferred phip_data class validation.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_resolve_paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve legacy-import paths and perform fast-fail argument checks — .ph_resolve_paths","text":"","code":".ph_resolve_paths(   exist_file = NULL,   fold_change_file = NULL,   samples_file = NULL,   input_file = NULL,   hit_file = NULL,   timepoints_file = NULL,   extra_cols = NULL,   output_dir = NULL,   data_long_path = NULL,   peptide_library = TRUE,   n_cores = NULL,   materialise_table = NULL,   auto_expand = NULL,   config_yaml = NULL )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_resolve_paths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve legacy-import paths and perform fast-fail argument checks — .ph_resolve_paths","text":"exist_file, fold_change_file, input_file, hit_file, samples_file, timepoints_file Character paths (relative absolute) respective CSV/Parquet inputs. NULL means \"supplied\". extra_cols Character vector extra metadata columns keep; may NULL. output_dir Ignored (soft-deprecated). config_yaml Optional path YAML file whose keys mirror function arguments; relative paths inside YAML resolved YAML’s directory.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_resolve_paths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resolve legacy-import paths and perform fast-fail argument checks — .ph_resolve_paths","text":"named list absolute paths, extra_cols, base_dir; suitable downstream helper functions.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_standard_read_duckdb_backend.html","id":null,"dir":"Reference","previous_headings":"","what":"Read and register ","title":"Read and register ","text":"internal function ingests one data files (Parquet CSV) specified cfg$data_long_path single DuckDB view named data_long, applying user-provided column mappings (colmap) rename source column standard PHIPERIO names. resulting phip_data object contains lazy DuckDB table can queried dplyr without loading full dataset R explicitly collected.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_standard_read_duckdb_backend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read and register ","text":"","code":".ph_standard_read_duckdb_backend(cfg, colmap)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_standard_read_duckdb_backend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read and register ","text":"cfg Named list, must contain element data_long_path pointing either single file directory files. Supported file extensions .parquet, .parq, .pq, .csv. colmap Named character list mapping standard PHIPERIO column names (e.g. \"sample_id\", \"peptide_id\", ...) actual column names found source files.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_standard_read_duckdb_backend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read and register ","text":"phip_data S3/S4 object (depending package implementation) whose data_long slot dplyr::tbl_dbi representing union source files. Calculations data_long remain lazy collect() called.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_standard_read_duckdb_backend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read and register ","text":"cfg$data_long_path directory, matching files within UNION 'ed. Parquet files read via parquet_scan(), CSV via read_csv_auto(). Column renaming performed SQL , R-level rename() calls needed. DuckDB VIEW called data_long created (dropped existed previously) downstream queries.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_sync_peptide_con.html","id":null,"dir":"Reference","previous_headings":"","what":"Sync peptide connection handle — .ph_sync_peptide_con","title":"Sync peptide connection handle — .ph_sync_peptide_con","text":"Ensures meta$peptide_con mirrors peptide library attribute.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_sync_peptide_con.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sync peptide connection handle — .ph_sync_peptide_con","text":"","code":".ph_sync_peptide_con(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_sync_peptide_con.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sync peptide connection handle — .ph_sync_peptide_con","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_sync_peptide_con.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sync peptide connection handle — .ph_sync_peptide_con","text":"phip_data object meta$peptide_con updated.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_warn — .ph_warn","title":"Internal helper: .ph_warn — .ph_warn","text":"Emit WARN log block using chk available.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_warn — .ph_warn","text":"","code":".ph_warn(headline, step = NULL, bullets = NULL, ...)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_with_timing.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_with_timing — .ph_with_timing","title":"Internal helper: .ph_with_timing — .ph_with_timing","text":"Conditionally raise formatted warning error.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_with_timing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_with_timing — .ph_with_timing","text":"","code":".ph_with_timing(   headline,   step = NULL,   bullets = NULL,   expr,   verbose = .ph_opt(\"verbose\", TRUE) )"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_word_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_word_list — .ph_word_list","title":"Internal helper: .ph_word_list — .ph_word_list","text":"Build human-readable list character vector, optional quoting conjunction handling.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_word_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_word_list — .ph_word_list","text":"","code":".ph_word_list(word_list = NULL, and_or = \"and\", is_are = FALSE, quotes = FALSE)"},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_wrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal helper: .ph_wrap — .ph_wrap","title":"Internal helper: .ph_wrap — .ph_wrap","text":"Wrap text configured width, preserving prefix.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/dot-ph_wrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal helper: .ph_wrap — .ph_wrap","text":"","code":".ph_wrap(text, prefix)"},{"path":"https://polymerase3.github.io/phiperio/reference/expand_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand to a full sample_id * peptide_id grid — expand_data","title":"Expand to a full sample_id * peptide_id grid — expand_data","text":"Create full Cartesian product samples peptides join back per-sample metadata. rows introduced expansion, numeric/integer columns filled 0 logical columns FALSE, unless overridden via fill_override.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/expand_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand to a full sample_id * peptide_id grid — expand_data","text":"","code":"expand_data(   x,   key_col = \"sample_id\",   id_col = \"peptide_id\",   fill_override = NULL,   add_exist = FALSE,   exist_col = \"exist\",   validate = TRUE,   ... )"},{"path":"https://polymerase3.github.io/phiperio/reference/expand_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand to a full sample_id * peptide_id grid — expand_data","text":"x <phip_data> object. key_col Name(s) sample identifier column(s). Character scalar vector, e.g. \"sample_id\" c(\"subject_id\", \"timepoint_factor\"). id_col Name peptide identifier column. Default \"peptide_id\". fill_override Optional named list fill values introduced rows, e.g. list(present = 0L, fold_change = NA_real_). User-provided entries take precedence defaults. add_exist TRUE, add integer existence flag (0/1) marking whether row present expansion. exist_col Name existence flag. column already exists, overwritten. validate Logical; TRUE, perform input checks required columns uniqueness. Set FALSE checks already performed upstream (e.g., inside validate_phip_data()). ... Reserved future extensions; currently unused.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/expand_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand to a full sample_id * peptide_id grid — expand_data","text":"updated <phip_data> object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/expand_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expand to a full sample_id * peptide_id grid — expand_data","text":"Updates x$data_long place (preserving laziness unless later compute() / collect()).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/expand_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand to a full sample_id * peptide_id grid — expand_data","text":"","code":"pd <- load_example_data() #> [12:00:26] INFO  Constructing <phip_data> object #>                  -> create_data() #> [12:00:26] INFO  Fetching peptide metadata library via get_peptide_library() #> [12:00:26] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:26] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:26] OK    Using cached peptide_meta (fast path) #> [12:00:26] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 0.052s #> [12:00:26] OK    Peptide metadata acquired #> [12:00:26] INFO  Validating <phip_data> #>                  -> validate_phip_data() #> [12:00:26] INFO  Checking structural requirements (shape & mandatory columns) #> [12:00:26] INFO  Checking outcome family availability (exist / fold_change / #>                  raw_counts) #> [12:00:26] INFO  Checking collisions with reserved names #>                    - subject_id, sample_id, timepoint, peptide_id, exist, #>                      fold_change, counts_input, counts_hit #> [12:00:26] INFO  Ensuring all columns are atomic (no list-cols) #> [12:00:26] INFO  Checking key uniqueness #> [12:00:27] INFO  Validating value ranges & types for outcomes #> [12:00:27] INFO  Assessing sparsity (NA/zero prevalence vs threshold) #>                    - warn threshold: 50% #> [12:00:27] INFO  Checking peptide_id coverage against peptide_library #> Warning: [12:00:27] WARN  peptide_id not found in peptide_library (e.g. 10003) #>                  -> peptide library coverage. #> [12:00:27] INFO  Checking full grid completeness (peptide * sample) #> Warning: [12:00:27] WARN  Counts table is not a full peptide * sample grid. #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> Warning: [12:00:27] WARN  Grid remains incomplete (auto_expand = FALSE). #>                  -> grid completeness #>                    - observed rows: 78200 #>                    - expected rows: 156000. #> [12:00:27] OK    Validating <phip_data> - done #>                  -> elapsed: 0.537s #> [12:00:27] OK    Constructing <phip_data> object - done #>                  -> elapsed: 0.59s pd <- expand_data(pd, fill_override = list(fold_change = NA_real_)) #> [12:00:27] INFO  Expanding <phip_data> to full grid #>                  -> updating x$data_long #> [12:00:27] INFO  Expanding to full key * id grid #>                  -> keys: 'sample_id'; id: 'peptide_id' #> [12:00:27] INFO  Checking uniqueness of (key, id) pairs #> [12:00:27] INFO  Type probe on lazy table #>                  -> collect(head 0) #> [12:00:27] INFO  Building Cartesian product of keys and ids #> [12:00:27] INFO  Detecting per-key constant (recyclable) columns #>                    - candidates: subject_id, group, timepoint, exist, #>                      counts_control, counts_hits, fold_change #> [12:00:27] OK    Column split decided #>                    - recyclable: subject_id, group, timepoint #>                    - non-recyclable: exist, counts_control, counts_hits, #>                      fold_change #> [12:00:27] INFO  Preparing fill defaults for introduced rows #>                    - numeric/integer: exist, fold_change, counts_control, #>                      counts_hits #>                    - logical: <none> #> [12:00:27] INFO  Applying user-provided fill overrides #>                    - overrides: fold_change #> [12:00:27] OK    Expanding to full key * id grid - done #>                  -> elapsed: 0.477s #> [12:00:28] INFO  Registering expanded table back to DB #>                    - name: 'data_long' #>                    - materialise_table: TRUE #> [12:00:28] INFO  Registering lazy table #>                  -> name: 'data_long'; as TABLE #> [12:00:28] INFO  Materialising via dplyr::compute() #> [12:00:28] OK    Registering lazy table - done #>                  -> elapsed: 0.278s #> [12:00:28] OK    Expanding <phip_data> to full grid - done #>                  -> elapsed: 1.381s"},{"path":"https://polymerase3.github.io/phiperio/reference/export_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Export a phip_data Table to Parquet — export_parquet","title":"Export a phip_data Table to Parquet — export_parquet","text":"Exports data_long table phip_data object disk Apache Parquet format.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/export_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export a phip_data Table to Parquet — export_parquet","text":"","code":"export_parquet(x, path)"},{"path":"https://polymerase3.github.io/phiperio/reference/export_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export a phip_data Table to Parquet — export_parquet","text":"x <phip_data> object data frame. path File path (character) save output .parquet file.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/export_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export a phip_data Table to Parquet — export_parquet","text":"NULL (invisibly).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/export_parquet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Export a phip_data Table to Parquet — export_parquet","text":"export performed directly efficiently database/lazy table without reading data memory.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/export_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export a phip_data Table to Parquet — export_parquet","text":"","code":"pd <- load_example_data() out_path <- tempfile(fileext = \".parquet\") export_parquet(pd, out_path) unlink(out_path)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the main PhIP-Seq counts table — get_counts","title":"Retrieve the main PhIP-Seq counts table — get_counts","text":"Quick accessor data_long slot phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the main PhIP-Seq counts table — get_counts","text":"","code":"get_counts(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the main PhIP-Seq counts table — get_counts","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the main PhIP-Seq counts table — get_counts","text":"tibble lazy table one row per peptide * sample pair.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the main PhIP-Seq counts table — get_counts","text":"","code":"pd <- load_example_data() tbl <- get_counts(pd)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_example_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Path to example PhIP-Seq datasets shipped with phiperio — get_example_path","title":"Path to example PhIP-Seq datasets shipped with phiperio — get_example_path","text":"Path example PhIP-Seq datasets shipped phiperio","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_example_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Path to example PhIP-Seq datasets shipped with phiperio — get_example_path","text":"","code":"get_example_path(name = c(\"phip_mixture\"))"},{"path":"https://polymerase3.github.io/phiperio/reference/get_example_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Path to example PhIP-Seq datasets shipped with phiperio — get_example_path","text":"name Character scalar. Name example dataset. Currently supported: \"phip_mixture\".","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_example_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Path to example PhIP-Seq datasets shipped with phiperio — get_example_path","text":"character scalar absolute path file.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_example_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Path to example PhIP-Seq datasets shipped with phiperio — get_example_path","text":"","code":"sim_path <- get_example_path(\"phip_mixture\") # phip_obj <- convert_standard(sim_path)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the metadata list — get_meta","title":"Retrieve the metadata list — get_meta","text":"Accesses meta slot, holds flags whether table full peptide * sample grid, available outcome columns, etc.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the metadata list — get_meta","text":"","code":"get_meta(x)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the metadata list — get_meta","text":"x valid phip_data object.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_meta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the metadata list — get_meta","text":"named list.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_meta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the metadata list — get_meta","text":"","code":"pd <- load_example_data() meta <- get_meta(pd)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_peptide_library.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","title":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","text":"function uses phiperio logging utilities consistent, ASCII-progress messages timing. Long-running steps bracketed .ph_with_timing(), informational/warning/error messages emitted via .ph_log_info(), .ph_log_ok(), .ph_warn(), .ph_abort(). Downloads RDS , sanitizes types (logical, character, numeric), writes DuckDB cache disk. Subsequent calls return lazy tbl_dbi without loading R memory.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_peptide_library.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","text":"","code":"get_peptide_library(force_refresh = FALSE)"},{"path":"https://polymerase3.github.io/phiperio/reference/get_peptide_library.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","text":"force_refresh Logical. TRUE, re-downloads rebuilds cache.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_peptide_library.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","text":"dplyr::tbl_dbi pointing peptide_meta table. returned object carries attribute \"duckdb_con\" open DBI connection.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/get_peptide_library.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","text":"Caching: persistent DuckDB database created user cache directory (via tools::R_user_dir(\"phiperio\", \"cache\")). can override location options(phiperio.cache_dir = \\\"...\\\"). force_refresh argument bypasses fast path rebuilds cache. Sanitization: Columns stripped attributes, list-columns flattened, textual \"NaN\" numeric NaN coerced NA. Binary 0/1 fields converted logical, \"TRUE\"/\"FALSE\" (case-insensitive) converted logical, numeric-looking character columns (beyond trivial 0/1) converted numeric. atomic types preserved. Integrity check: SHA-256 checksum provided, warning logged downloaded file’s checksum match expected value.","code":""},{"path":[]},{"path":"https://polymerase3.github.io/phiperio/reference/get_peptide_library.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the peptide metadata table into DuckDB, forcing atomic types — get_peptide_library","text":"","code":"lib <- get_peptide_library() #> [12:00:29] INFO  Retrieving peptide metadata into DuckDB cache #>                  -> get_peptide_library(force_refresh = FALSE) #> [12:00:29] INFO  Opened DuckDB connection #>                    - cache dir: #>                      /home/runner/.cache/R/phiperio/peptide_meta/phip_cache.duckdb #>                    - table: peptide_meta #> [12:00:29] OK    Using cached peptide_meta (fast path) #> [12:00:29] OK    Retrieving peptide metadata into DuckDB cache - done #>                  -> elapsed: 0.044s"},{"path":"https://polymerase3.github.io/phiperio/reference/load_example_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Example PhIP-Seq Dataset as <phip_data> — load_example_data","title":"Load Example PhIP-Seq Dataset as <phip_data> — load_example_data","text":"Convenience helper quickly load shipped example dataset (\"phip_mixture\") <phip_data> object, suitable downstream analysis visualization. function wraps convert_standard, automatically supplying correct parameters included example data.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/load_example_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Example PhIP-Seq Dataset as <phip_data> — load_example_data","text":"","code":"load_example_data(name = c(\"phip_mixture\", \"small_mixture\"))"},{"path":"https://polymerase3.github.io/phiperio/reference/load_example_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load Example PhIP-Seq Dataset as <phip_data> — load_example_data","text":"name Character scalar. Name shipped example dataset. Currently supported: \"phip_mixture\", \"small_mixture\".","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/load_example_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Example PhIP-Seq Dataset as <phip_data> — load_example_data","text":"<phip_data> object created chosen example dataset.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/load_example_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load Example PhIP-Seq Dataset as <phip_data> — load_example_data","text":"","code":"# Load the example data shipped with the package: ex <- load_example_data() # ex is now a <phip_data> object ready for analysis  # Specify the dataset name explicitly ex2 <- load_example_data(\"small_mixture\")  # Use with downstream analysis/plotting functions as needed"},{"path":"https://polymerase3.github.io/phiperio/reference/merge.phip_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge or join a phip_data object — merge.phip_data","title":"Merge or join a phip_data object — merge.phip_data","text":"Merge join phip_data object","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/merge.phip_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge or join a phip_data object — merge.phip_data","text":"","code":"# S3 method for class 'phip_data' merge(x, y, ...)"},{"path":"https://polymerase3.github.io/phiperio/reference/merge.phip_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge or join a phip_data object — merge.phip_data","text":"x phip_data object. y data-frame-like object another phip_data. ... Arguments forwarded either base::merge() chosen dplyr join (e.g. =, suffix =, etc.).","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/merge.phip_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge or join a phip_data object — merge.phip_data","text":"new phip_data whose data_long contains merged / joined tibble.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/merge.phip_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge or join a phip_data object — merge.phip_data","text":"","code":"pd <- load_example_data() merged <- merge(pd, pd, by = c(\"sample_id\", \"peptide_id\")) #> Warning: [12:00:30] WARN  `merge()` copies both tables in full; this may exhaust RAM."},{"path":"https://polymerase3.github.io/phiperio/reference/phip_data_join.html","id":null,"dir":"Reference","previous_headings":"","what":"dplyr joins for phip_data — phip_data_join","title":"dplyr joins for phip_data — phip_data_join","text":"dplyr joins phip_data","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/phip_data_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dplyr joins for phip_data — phip_data_join","text":"","code":"# S3 method for class 'phip_data' left_join(x, y, ...)  # S3 method for class 'phip_data' right_join(x, y, ...)  # S3 method for class 'phip_data' inner_join(x, y, ...)  # S3 method for class 'phip_data' full_join(x, y, ...)  # S3 method for class 'phip_data' semi_join(x, y, ...)  # S3 method for class 'phip_data' anti_join(x, y, ...)"},{"path":"https://polymerase3.github.io/phiperio/reference/phip_data_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dplyr joins for phip_data — phip_data_join","text":"x phip_data object. y phip_data data frame / tbl. ... Passed corresponding dplyr::<join> function.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/phip_data_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dplyr joins for phip_data — phip_data_join","text":"phip_data object updated data_long.","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/phip_data_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dplyr joins for phip_data — phip_data_join","text":"","code":"pd <- load_example_data() joined <- dplyr::left_join(pd, pd, by = c(\"sample_id\", \"peptide_id\"))"},{"path":"https://polymerase3.github.io/phiperio/reference/phiperio-package.html","id":null,"dir":"Reference","previous_headings":"","what":"phiperio — phiperio-package","title":"phiperio — phiperio-package","text":"Provides utilities import, validate, manage PhIP-Seq datasets, including standardized conversion pipelines, data checks, access cached peptide metadata.","code":""},{"path":[]},{"path":"https://polymerase3.github.io/phiperio/reference/phiperio-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"phiperio — phiperio-package","text":"Maintainer: Mateusz Kolek mati.kolek13@gmail.com (ORCID) [copyright holder] contributors: Alon Alexander .alexander@umcg.nl [contributor, copyright holder]","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/validate_phip_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal validator for <phip_data> objects — validate_phip_data","title":"Internal validator for <phip_data> objects — validate_phip_data","text":"Internal validator <phip_data> objects","code":""},{"path":"https://polymerase3.github.io/phiperio/reference/validate_phip_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal validator for <phip_data> objects — validate_phip_data","text":"","code":"validate_phip_data(x, na_warn_thresh = 0.5, auto_expand = TRUE)"},{"path":"https://polymerase3.github.io/phiperio/news/index.html","id":"phiperio-040","dir":"Changelog","previous_headings":"","what":"phiperio 0.4.0","title":"phiperio 0.4.0","text":"Make examples self-contained reliable: fix convert_standard() example use temp CSV, switch expand_data() example load_example_data(), remove examples internal helpers. Remove \\donttest{} / \\dontrun{} wrappers examples R Rd files run checks. Harden load_example_data() caching rebuilding cached object’s DuckDB connection longer valid. Significantly improved coverage.","code":""},{"path":"https://polymerase3.github.io/phiperio/news/index.html","id":"phiperio-030","dir":"Changelog","previous_headings":"","what":"phiperio 0.3.0","title":"phiperio 0.3.0","text":"Rename exported API verb_noun naming (e.g., create_data, convert_standard, convert_legacy, load_example_data, get_example_path, expand_data) align docs/tests. Rename internal helpers .ph_ prefix add internal roxygen docs. Reorganize R/utils.R themed sections clearer helper descriptions. Centralize connection teardown via close.phip_data() GC finalizer connection sync helpers. Persist peptide metadata cache user cache dir reuse cached downloads SHA-256 validation. Improve peptide library preview columns print.phip_data(). Update file naming R/ consistent convention. Adjust validation flow reduce duplication around full-grid checks. Update DESCRIPTION metadata (title, authors, description, dependencies).","code":""},{"path":"https://polymerase3.github.io/phiperio/news/index.html","id":"phiperio-020","dir":"Changelog","previous_headings":"","what":"phiperio 0.2.0","title":"phiperio 0.2.0","text":"Remove comparisons/contrasts mechanics, validation, tests, mock files. Add centralized connection teardown via close.phip_data() internal helpers; attach auto-finalizer GC cleanup. Reduce duplicate validation consolidating full-grid checks validate_phip_data() adding optional validation toggles expansion. Clean unused globals R/zzz.R remove unused utils helpers. Update tests docs reflect new API validation flow.","code":""},{"path":"https://polymerase3.github.io/phiperio/news/index.html","id":"phiperio-010","dir":"Changelog","previous_headings":"","what":"phiperio 0.1.0","title":"phiperio 0.1.0","text":"Initial release IO/convert functionality migrated phiper.","code":""}]
